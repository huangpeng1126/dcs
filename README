Dependency-Based Compositional Semantics (DCS)
Release 1.0
September 9, 2011

This is an implementation of the following paper:
Percy Liang, Michael I. Jordan, Dan Klein.  Learning Dependency-Based Semantics.  ACL 2011.
http://cs.stanford.edu/~pliang/papers/dcs-acl2011.pdf

Requirements
============
This code has been tested on Linux with Java 1.7.0, Scala 2.9.0.1, and Ruby 1.8.7.
It might also work with older/newer versions of the above, but there are no guarantees.
Note that you don't actually need Scala on your system to run the code because
the Scala JARs are included for your convenience.
If you change the code, simply type 'make' to re-compile.
For convenience, all source code is also packaged into the JAR files.

Running
=======
Type ./dcs @geo to train/test a model using the default settings on the GEO dataset.
Type ./dcs @job for the JOB dataset.
Everything will be output to state/execs/<i>.exec, where i is the first available integer;
what is printed to stdout is stored in the 'log' file; the 'record' file gives a summary of the important statistics.
Type ./dcs @geo -help to see all the options.
Type ./dcs @geo %pretend to output the shell command that is actually run.
Edit the dcs script to change the various options (this uses execrunner library
- see external/execrunner.rb for more details).
Type ./dcs @geodemo to launch a webserver (on port 8400) which allows you to
use a trained model to answer new questions.

Structure
=========
dcs: the main script to run to launch the DCS system.
external: libraries and scripts that DCS depends on
src: all the DCS source code
domains: where the GEO and JOB datasets live as well as the lexical triggers and predicates that we use.
state/execs: each run of the dcs script generates a new directory which is stored here (to be generated).

Code
====
The main files are as follows:
- NuggetLearn.scala: main entry point
- InferState.scala: bottom-up construction mechanism for building DCS trees and computation of features
- Learner.scala: performers parameter estimation and optimization
- DatalogInterpreter.scala: interprets Datalog files, also with special statements (which begin with _); used mainly for setting up the world before learning happens.
In this project, we use term "Datalog" loosely to refer to the syntax of the
rules that are used to define the data.  Unlike real Datalog, rules are
executed once in sequential order; there is no recursion.

Data
====
All the data is stored in the domains directory and all files are in Datalog format (*.dlog).
Each domain specifies the predicates in predicates.dlog.
The lexical triggers are specified in lexicon*.dlog.
The general directory is used by all domains and contains domain-independent predicates and lexical triggers.
The database/world and training/test examples were originally obtained from the original source
http://www.cs.utexas.edu/users/ml/geo.html
but were adapted and cleaned up for our purposes.
For the most part, the file formats are compatible with the original Prolog,
but remember that our files are not full-blown Prolog.

============================================================
(C) Copyright 2011, Percy Liang

http://cs.berkeley.edu/~pliang

Permission is granted for anyone to copy, use, or modify these programs and
accompanying documents for purposes of research or education, provided this
copyright notice is retained, and note is made of any changes that have been
made.

These programs and documents are distributed without any warranty, express or
implied.  As the programs were written for research purposes only, they have
not been tested to the degree that would be advisable in any important
application.  All use of these programs is entirely at the user's own risk.

============================================================

Change history
--------------
1.0: initial release
